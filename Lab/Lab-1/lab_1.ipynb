{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Write a PySpark program to square set of integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkConf\n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----------+\n",
      "|int|squared_int|\n",
      "+---+-----------+\n",
      "|  1|          1|\n",
      "|  2|          4|\n",
      "|  3|          9|\n",
      "|  4|         16|\n",
      "+---+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName('SquaredIntegers').getOrCreate()\n",
    "data = pd.DataFrame({'int':[1,2,3,4]})\n",
    "data.to_csv('data.csv',index=False)\n",
    "df_pyspark = spark.read.csv('data.csv',header=True,inferSchema=True) \n",
    "#df_pyspark.show()\n",
    "df_squared = df_pyspark.withColumn('squared_int',(df_pyspark['int']**2).cast('int'))\n",
    "df_squared.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 2. Write a PySpark program to find the maximum of given set of numbers.\n",
    " 3. Write a PySpark program to find average of N numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- int: integer (nullable = true)\n",
      " |-- float: double (nullable = true)\n",
      " |-- int_arrays: string (nullable = true)\n",
      "\n",
      "+---+-----+------------+\n",
      "|int|float|  int_arrays|\n",
      "+---+-----+------------+\n",
      "|  1| -1.0|      [1, 2]|\n",
      "|  2|  0.5|   [3, 4, 5]|\n",
      "|  3|  2.7|[6, 7, 8, 9]|\n",
      "+---+-----+------------+\n",
      "\n",
      "+-------+---------+------------+\n",
      "|max_int|max_float| max_int_arr|\n",
      "+-------+---------+------------+\n",
      "|      3|      2.7|[6, 7, 8, 9]|\n",
      "+-------+---------+------------+\n",
      "\n",
      "+-------+------------------+\n",
      "|avg_int|         avg_float|\n",
      "+-------+------------------+\n",
      "|    2.0|0.7333333333333334|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkContext\n",
    "from pyspark import SparkConf \n",
    "import pandas as pd \n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "data2 = pd.DataFrame({'int':[1,2,3],\n",
    "                      'float':[-1.0,0.5,2.7],\n",
    "                      'int_arrays':[[1,2],[3,4,5],[6,7,8,9]]})\n",
    "spark = SparkSession.builder.appName('Max').getOrCreate()\n",
    "data2.to_csv('data2.csv',index=False)\n",
    "df_pyspark = spark.read.csv('data2.csv',header=True,inferSchema=True)\n",
    "df_pyspark.printSchema()\n",
    "df_pyspark.show()\n",
    "#Q2\n",
    "max_result = df_pyspark.agg(F.max('int').alias('max_int'),F.max('float').alias('max_float'),F.max('int_arrays').alias('max_int_arr'))\n",
    "max_result.show()\n",
    "#Q3\n",
    "avg_result = df_pyspark.agg(F.avg('int').alias('avg_int'),F.avg('float').alias('avg_float'))\n",
    "avg_result.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Demonstrate how to read a CSV file into a PySpark DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+----------+\n",
      "|   Name|Age|Experience|\n",
      "+-------+---+----------+\n",
      "|   Sam | 19|         1|\n",
      "|Anthony| 21|         2|\n",
      "| James | 24|         5|\n",
      "+-------+---+----------+\n",
      "\n",
      "root\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Age: integer (nullable = true)\n",
      " |-- Experience: integer (nullable = true)\n",
      "\n",
      "+-------+-------+------------------+------------------+\n",
      "|summary|   Name|               Age|        Experience|\n",
      "+-------+-------+------------------+------------------+\n",
      "|  count|      3|                 3|                 3|\n",
      "|   mean|   NULL|21.333333333333332|2.6666666666666665|\n",
      "| stddev|   NULL|2.5166114784235836|2.0816659994661326|\n",
      "|    min|Anthony|                19|                 1|\n",
      "|    max|   Sam |                24|                 5|\n",
      "+-------+-------+------------------+------------------+\n",
      "\n",
      "+-------+------------------+\n",
      "|summary|               Age|\n",
      "+-------+------------------+\n",
      "|  count|                 3|\n",
      "|   mean|21.333333333333332|\n",
      "| stddev|2.5166114784235836|\n",
      "|    min|                19|\n",
      "|    max|                24|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('File_Manipulation').getOrCreate()\n",
    "#Q4\n",
    "df_pyspark = spark.read.csv('test1.csv',header=True,inferSchema=True)\n",
    "#Q5 display the first few rows and schema of a DataFrame\n",
    "df_pyspark.show()\n",
    "df_pyspark.printSchema()\n",
    "#Q6 basic summary statistics for a specific column in the DataFrame\n",
    "df_pyspark.describe().show()\n",
    "df_pyspark.select('Age').describe().show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
